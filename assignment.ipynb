{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8V6JYhDuVt4",
        "outputId": "1db0e692-1717-4ff4-aede-1cb5c3b941b2"
      },

      "source": [
        "!git clone https://github.com/koolsterre/TM10007_ML_Project_group_9.git\n",
        "%cd TM10007_ML_Project_group_9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CiDn2Sk-VWqE"
      },
      "outputs": [],
      "source": [
        "\"\"\"Importing libraries and packages\"\"\"\n",
        "# General packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Preprocessing and Classifiers\n",
        "from sklearn import model_selection\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from worclipo.load_data import load_data\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "#Importing our own functinos\n",
        "from outliers import replace_outliers\n",
        "from outliers import replace_outliers_test\n",
        "from prepro_data import processing_data_scaling\n",
        "from prepro_data import processing_data_scaling_test\n",
        "from prepro_data import processing_data_rfecv\n",
        "from prepro_data import processing_data_rfecv_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-KjMi5JsGaa"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",

      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "1d81cef2-43f8-44ca-d2dd-b73098303b9c"
      },

      "source": [
        "\"\"\"Data loading\"\"\"\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzIkNrXosGae",
        "outputId": "4ba8fb8a-6047-4d8d-8a79-6c7baff5a984"
      },
      "outputs": [],
      "source": [
        "\"\"\"Check for duplicate patients\"\"\"\n",
        "duplicates = data[data.duplicated(keep=False)]\n",
        "data = data.drop_duplicates(keep='first')\n",
        "print(f\"Number of rows after checking for duplicates: {len(data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_4GGQyAsGaf",
        "outputId": "3eff6c95-f4b5-40ca-e23f-96f3fb656989"
      },
      "outputs": [],
      "source": [
        "\"\"\"Check for missing values\"\"\"\n",
        "data_missing_values = data.replace(' ', np.nan)\n",
        "missing_values = data[data.isnull().any(axis=1)]\n",
        "\n",
        "if not missing_values.empty:\n",
        "    print(f\"Missing values; {missing_values}\")\n",
        "else:\n",
        "    print(\"No missing values\")\n"
      ]
    },
    {
      "cell_type": "code",

      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGYIhXOwsGag",
        "outputId": "bfafba25-f5e3-42e9-97ac-0da89351d549"
      },
      "outputs": [],
      "source": [
        "\"\"\"Splitting the data into a test and training dataset: outer cross-validation\"\"\"\n",
        "data_train, data_test = model_selection.train_test_split(data, test_size=0.20, random_state=42)\n",
        "print(f'The number of samples train: {len(data_train.index)}')\n",
        "print(f'The number of columns train: {len(data_train.columns)}')\n",
        "print(f'The number of samples test: {len(data_test.index)}')\n",
        "print(f'The number of columns test: {len(data_test.columns)}')"
      ]
    },
    {
      "cell_type": "code",

      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML-MkkHasGai",
        "outputId": "3d965be9-a91e-4240-a6ea-f7d6b68a5721"
      },

      "source": [
        "\"\"\"Check for normal distribution and detect and replace outliers\"\"\"\n",
        "\n",
        "# Alleen numerieke kolommen selecteren\n",
        "numeric_cols = data_train.select_dtypes(include=['number'])\n",
        "results = []\n",
        "\n",
        "for col in numeric_cols.columns:\n",
        "    data = numeric_cols[col].dropna()\n",
        "    stat, p = shapiro(data)\n",
        "    is_normaal = p > 0.05\n",
        "\n",
        "    results.append({\n",
        "        'Kolom': col,\n",
        "        'Shapiro_p': p,\n",
        "        'Normaal': is_normaal\n",
        "    })\n",
        "\n",
        "result_df = pd.DataFrame(results)\n",
        "print(result_df)\n",
        "\n",
        "data_train, total_capped, lower_bound, upper_bound = replace_outliers(data_train)\n",
        "print(\"\\nTotal number of captured outliers in the train data:\", total_capped)\n",
        "\n",
        "data_test, total_capped_test = replace_outliers_test(data_train, data_test, lower_bound, upper_bound)\n",
        "print(\"\\nTotal number of captured outliers in the test data:\", total_capped_test)"
      ]
    },
    {
      "cell_type": "code",

      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uMpQJZ2sGaj",
        "outputId": "db9710a5-252a-477b-eda0-3f6dc9a55f33"
      },
      "outputs": [],
      "source": [
        "\"\"\"\"Preprocessing the data\"\"\"\n",
        "#This data is scaled using MinMaxScaler, and a variance and correlation threshold are applied\n",
        "\n",
        "#Train data\n",
        "df_label_scaling, df_processed_scaling, variance_data, selected_columns, drop_correlation, scaler = processing_data_scaling(data_train)\n",
        "\n",
        "#Test data\n",
        "df_label_scaling_test, df_processed_scaling_test = processing_data_scaling_test(data_test, variance_data, selected_columns, drop_correlation, scaler)\n",
        "\n",
        "#df_processed_scaling and df_processed_scaling are the inputs for kNN and RF"
      ]
    },
    {
      "cell_type": "code",

      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XNYBDu8CsGak",
        "outputId": "820b0d1a-65b7-4fd7-cee0-102f8908ca82"
      },

      "source": [
        "\"\"\"Preprocessing the data including RFECV\"\"\"\n",
        "#This data is scaled (standardized), a variance and correlation threshold are applied,\n",
        "# and RFECV brought back the number of features to 18\n",
        "\n",
        "#Train data\n",
        "data_rfecv, df_label, variance_data, selected_columns, drop_correlation, scaler, rfecv, selected_features = processing_data_rfecv(data_train)\n",
        "\n",
        "#Test data\n",
        "data_rfecv_test, df_label_rfecv_test = processing_data_rfecv_test(data_test, variance_data, selected_columns, drop_correlation, scaler, rfecv, selected_features)\n",
        "\n",
        "#data_rfecv and data_rfecv_test are the inputs for the SVM"
      ]
    },
    {
      "cell_type": "code",

      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdtTbR52sGal",
        "outputId": "b1eac275-626c-4f16-e49b-018bcc2e6e16"
      },
      "outputs": [],
      "source": [
        "\"\"\"Support Vector Machine\"\"\"\n",
        "# Defining the data to use for this classifier\n",
        "X = data_rfecv  # Features\n",
        "\n",
        "# Set up the parameter grid for GridSearchCV\n",
        "param_grid = [\n",
        "    {'kernel': ['linear'], 'C': [0.1, 1, 10]},\n",
        "    {'kernel': ['rbf'], 'C': [0.1, 1, 10], 'gamma': ['scale', 'auto', 0.1, 1]},\n",
        "    {'kernel': ['poly'], 'C': [0.1, 1, 10], 'degree': [3, 4, 5], 'gamma': ['scale', 'auto', 0.1, 1], 'coef0': [0.0, 0.1, 0.5]},\n",
        "]\n",
        "\n",
        "# Set up the SVM classifier\n",
        "svm_classifier = SVC(random_state=42, probability=True)  # Enable probability for AUC calculation\n",
        "\n",
        "# Set up inner cross-validation for hyperparameter tuning\n",
        "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Set up GridSearchCV to search for the best hyperparameters\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=svm_classifier,\n",
        "    param_grid=param_grid,\n",
        "    scoring='roc_auc',         # Optimize AUC score\n",
        "    refit=True,                # Refit best model on full training data\n",
        "    cv=inner_cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Perform the grid search on the training data to find the best hyperparameters\n",
        "grid_search.fit(X, Y)\n",
        "\n",
        "# Get the best model (with the best hyperparameters)\n",
        "best_model_svm = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions to evaluate performance\n",
        "y_pred = best_model_svm.predict(X)\n",
        "y_pred_proba = best_model_svm.predict_proba(X)[:, 1]  # Probability estimates for AUC\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "auc_score = roc_auc_score(Y, y_pred_proba)\n",
        "\n",
        "# Print results\n",
        "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
        "print(f\"Training AUC: {auc_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",

      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzk-Jt6psGam",
        "outputId": "a02ee8c2-01e9-4c26-bc5c-e912c6432609"
      },

      "source": [
        "\"\"\"Random Forest Classifier\"\"\"\n",
        "# Defining the data to use for this classifier\n",
        "X = df_processed_scaling # Features\n",
        "\n",
        "# Set up parameter grid for Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_leaf': [4, 5, 10, 15, 20],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Inner CV for hyperparameter tuning\n",
        "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Set up GridSearchCV to search for best hyperparameters\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf_classifier,\n",
        "    param_grid=param_grid,\n",
        "    scoring='roc_auc',\n",
        "    refit=True,\n",
        "    cv=inner_cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X, Y)\n",
        "\n",
        "# Best model after Grid Search\n",
        "best_model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "y_pred = best_model_rf.predict(X)\n",
        "y_pred_proba = best_model_rf.predict_proba(X)[:, 1]  # Probability for positive class\n",
        "\n",
        "# Evaluate model performance\n",
        "auc_score = roc_auc_score(Y, y_pred_proba)\n",
        "\n",
        "# Print results\n",
        "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
        "print(f\"Training AUC: {auc_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",

      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfVZWYF5sGao",
        "outputId": "2a695363-c967-420e-9099-5cf1997f62a6"
      },

      "source": [
        "\"\"\"KNNeighbour classifier\"\"\"\n",
        "# Defining the data to use for this classifier\n",
        "X = df_processed_scaling # Features\n",
        "\n",
        "# Set up the parameter grid for GridSearchCV (for KNN, we mainly tune 'n_neighbors', 'weights', and 'metric')\n",
        "param_grid = {\n",
        "    'n_neighbors': [5, 7, 10, 15, 20],  # Trying different values for k (number of neighbors)\n",
        "    'weights': ['uniform', 'distance'],  # Weighting of neighbors\n",
        "    'metric': ['euclidean', 'manhattan']  # Distance metrics to use\n",
        "}\n",
        "\n",
        "# Set up the KNN classifier\n",
        "knn_classifier = KNeighborsClassifier()  # KNN classifier\n",
        "\n",
        "# Set up inner cross-validation for hyperparameter tuning\n",
        "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Set up GridSearchCV to search for the best hyperparameters\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=knn_classifier,\n",
        "    param_grid=param_grid,\n",
        "    cv=inner_cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    scoring='roc_auc',         # Optimize AUC score\n",
        "    refit=True,                # Refit best model on full training data\n",
        ")\n",
        "\n",
        "# Perform the grid search on the training data to find the best hyperparameters\n",
        "grid_search.fit(X, Y)\n",
        "\n",
        "# Get the best model (with the best hyperparameters)\n",
        "best_model_knn = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions to evaluate performance\n",
        "y_pred = best_model_knn.predict(X)\n",
        "y_pred_proba = best_model_knn.predict_proba(X)[:, 1]  # Probability estimates for AUC\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "auc_score = roc_auc_score(Y, y_pred_proba)\n",
        "\n",
        "# Print results\n",
        "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
        "print(f\"Training AUC: {auc_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",

      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0R62yDdsGap",
        "outputId": "41c4bea7-e57e-481b-8c83-5440fb0c0dbd"
      },

      "source": [
        "\"\"\"Testing the classifiers on the test data\"\"\"\n",
        "X = data_rfecv_test  # Features\n",
        "Y = label_encoder.transform(df_label_rfecv_test['label'])  # Encoded labels\n",
        "\n",
        "clsfs = [best_model_svm, best_model_rf, best_model_knn]\n",
        "classifier_names = ['SVM', 'Random Forest', 'KNN']\n",
        "\n",
        "# Lists to store metrics\n",
        "accuracies = []\n",
        "aucs = []\n",
        "f1s = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "for clf in clsfs:\n",
        "    y_pred = clf.predict(X)\n",
        "\n",
        "    # If predictions are strings, encode them\n",
        "    if isinstance(y_pred[0], str):\n",
        "        y_pred = label_encoder.transform(y_pred)\n",
        "\n",
        "    if hasattr(clf, 'predict_proba'):\n",
        "        y_score = clf.predict_proba(X)[:, 1]\n",
        "    else:\n",
        "        y_score = y_pred\n",
        "\n",
        "    # Compute metrics\n",
        "    auc = metrics.roc_auc_score(Y, y_score)\n",
        "    accuracy = metrics.accuracy_score(Y, y_pred)\n",
        "    f1 = metrics.f1_score(Y, y_pred, pos_label=1)\n",
        "    precision = metrics.precision_score(Y, y_pred, pos_label=1)\n",
        "    recall = metrics.recall_score(Y, y_pred, pos_label=1)\n",
        "\n",
        "    # Save them for plotting\n",
        "    accuracies.append(accuracy)\n",
        "    aucs.append(auc)\n",
        "    f1s.append(f1)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "\n",
        "    # Optional: print for debugging\n",
        "    print(type(clf))\n",

        "\n",
        "\n",
        "\"\"\"Plotting the classifier performances dynamically\"\"\"\n",
        "metrics_names = ['Accuracy', 'AUC', 'F1-score', 'Precision', 'Recall']\n",
        "metric_values = np.array([accuracies, aucs, f1s, precisions, recalls]).T\n",
        "\n",
        "x = np.arange(len(metrics_names))\n",
        "bar_width = 0.25\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "bars = []\n",
        "\n",
        "# Plot each classifier's metrics\n",
        "for i, classifier in enumerate(classifier_names):\n",
        "    bars.append(ax.bar(x + (i - 1) * bar_width, metric_values[i], bar_width, label=classifier))\n",
        "\n",
        "# Labels and ticks\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Classifier Performance')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics_names)\n",
        "ax.set_ylim(0, 1.1)\n",
        "ax.legend()\n",
        "\n",
        "# Add labels to bars\n",
        "def add_labels(bar_group):\n",
        "    for bar in bar_group:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height:.2f}',\n",
        "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                    xytext=(0, 3),\n",
        "                    textcoords='offset points',\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "for bar_group in bars:\n",
        "    add_labels(bar_group)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "KT-2023",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
